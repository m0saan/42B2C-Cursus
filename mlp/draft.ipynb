{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc110b3-d858-4e5c-ae9e-695d78f4a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minima as mi\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809930a-1765-4787-bcda-3543ea139a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minima as mi\n",
    "import numpy as np\n",
    "import minima.nn as nn\n",
    "import minima.optim as optim\n",
    "from minima.data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994ae0a-af40-4c59-b990-baa42a0eb730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    count = 0\n",
    "    for i in range(len(out)):\n",
    "        if out[i].item() == yb[i].item():\n",
    "            count += 1\n",
    "    return count / len(out)\n",
    "    # return (out.argmax(dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69725eb4-f97e-4b78-8fe4-745306985b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    labels_path = os.path.join(path,\n",
    "                               '%s-labels-idx1-ubyte.gz'\n",
    "                               % kind)\n",
    "    images_path = os.path.join(path,\n",
    "                               '%s-images-idx3-ubyte.gz'\n",
    "                               % kind)\n",
    "\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def normalize(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data\n",
    "\n",
    "\n",
    "X_train, y_train = load_mnist('datasets/fashion', kind='train')\n",
    "X_test, y_test = load_mnist('datasets/fashion', kind='t10k')\n",
    "\n",
    "X_train = np.copy(X_train)\n",
    "X_test = np.copy(X_test)\n",
    "X_train = X_train / np.array(255.0, dtype=np.float64)\n",
    "X_test = X_test / np.array(255.0, dtype=np.float64)\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc10bd7-0a2e-4bf2-bf60-324b57846c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebbaf7-3e2c-4cce-a674-468d6392ec32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c6215-dec9-4842-b181-ad46478c84f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749c4de6-7501-472c-8683-0e829fea8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, y_tr, X_val, y_val = map(mi.Tensor, (X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c532b0b-e5d0-4b02-9147-c41bde251295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(minima.autograd.Tensor, mi.Tensor([9 0 0 3 0 2 7 2 5 5]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_tr), y_tr[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae78809e-cf3d-4785-9cac-51791b6014f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (dense1): Linear(in_features=784, out_features=24, bias=True)\n",
       "  (dense2): Linear(in_features=24, out_features=24, bias=True)\n",
       "  (dense3): Linear(in_features=24, out_features=24, bias=True)\n",
       "  (dense4): Linear(in_features=24, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.dense1 = nn.Linear(in_features=input_shape, out_features=24)\n",
    "        self.dense2 = nn.Linear(24, 24)\n",
    "        self.dense3 = nn.Linear(24, 24)\n",
    "        self.dense4 = nn.Linear(24, output_shape)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.relu(self.dense2(x))\n",
    "        x = self.relu(self.dense3(x))\n",
    "        # print(self.dense4(x))\n",
    "        x = self.dense4(x)\n",
    "        return x\n",
    "\n",
    "# Create the neural network\n",
    "input_shape = X_tr.shape[1]  # Replace with the actual input shape\n",
    "output_shape = 10  # Replace with the actual output shape\n",
    "\n",
    "network = NeuralNetwork(input_shape, output_shape)\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef181957-a72c-4afc-bf9a-ba3bbe9fd68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = mi.Tensor(X)\n",
    "        self.y = mi.Tensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "\n",
    "tr_ds = MyDataset(X_tr, y_tr)\n",
    "val_ds = MyDataset(X_val, y_val)\n",
    "\n",
    "# Creating the data loader\n",
    "batch_size = 10\n",
    "tr_dl = DataLoader(tr_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ee356-04c7-4022-8216-997a0791afdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), mi.Tensor([6 6 7 6 9 9 3 4 6 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(tr_dl))\n",
    "xb.shape, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5b8b7-9c7c-4a53-8027-8621b225059a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.010457627275600019, 1.0153364259848787)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.numpy().mean(), xb.numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5c722-58eb-4455-8dd9-70495c6c2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    network = NeuralNetwork(input_shape, output_shape)\n",
    "    opt = optim.SGD(network.parameters(), lr=0.01)\n",
    "    bce = nn.CrossEntropyLoss()\n",
    "    \n",
    "    network.train()\n",
    "    num_epochs = 10\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        # Training phase\n",
    "        network.train()\n",
    "        tot_loss,tot_acc,count = 0.,0.,0\n",
    "        for xb, yb in tr_dl:\n",
    "            preds = network(xb)\n",
    "            loss = bce(preds, yb)\n",
    "            # import pdb; pdb.set_trace()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # Calculate accuracy & loss\n",
    "            predicted_labels = preds.argmax(axis=1)\n",
    "            n = len(xb)\n",
    "            count += n\n",
    "            tot_loss += loss.item()*n\n",
    "            tot_acc  += mi.Tensor.accuracy(predicted_labels, yb).item()*n\n",
    "        \n",
    "        # Print epoch-wise loss and accuracy\n",
    "        # print(f\"epoch {epoch + 1:02d}/{num_epochs:02d} - loss: {avg_train_loss:.4f} - acc: {avg_train_acc:.4f} - val_loss: {avg_val_loss:.4f} - val_acc: {avg_val_acc:.4f}\")\n",
    "        print(f\"epoch {epoch + 1:02d}/{num_epochs:02d} - loss: {tot_loss/count:.4f} - acc: {tot_acc/count:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883c955-280f-4c67-9cab-728e42cb5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01/10 - loss: 0.5462 - acc: 0.8011\n",
      "epoch 02/10 - loss: 0.4102 - acc: 0.8499\n",
      "epoch 03/10 - loss: 0.3750 - acc: 0.8635\n",
      "epoch 04/10 - loss: 0.3546 - acc: 0.8710\n",
      "epoch 05/10 - loss: 0.3382 - acc: 0.8776\n",
      "epoch 06/10 - loss: 0.3279 - acc: 0.8794\n",
      "epoch 07/10 - loss: 0.3175 - acc: 0.8825\n",
      "epoch 08/10 - loss: 0.3086 - acc: 0.8864\n",
      "epoch 09/10 - loss: 0.3024 - acc: 0.8880\n",
      "epoch 10/10 - loss: 0.2961 - acc: 0.8917\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e3417-548f-47f6-b5c2-7f0aed42f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eac392-270b-4b25-aa38-0795de0a7921",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0105a2-9bad-4070-9fb1-2f5c67ebb38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, loss_func, opt_fn, train_dl, valid_dl):\n",
    "    opt = opt_fn(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_tot_loss, train_tot_acc, t_count = 0.,0.,0\n",
    "        for xb,yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            # Calculate accuracy & loss\n",
    "            predicted_labels = preds.argmax(axis=1)\n",
    "            n = len(xb)\n",
    "            t_count += n\n",
    "            train_tot_loss += loss.item()*n\n",
    "            train_tot_acc  += mi.Tensor.accuracy(predicted_labels, yb).item()*n\n",
    "\n",
    "            \n",
    "\n",
    "        model.eval()\n",
    "        # with torch.no_grad():\n",
    "            val_tot_loss, val_tot_acc,v_count = 0.,0.,0\n",
    "            for xb,yb in valid_dl:\n",
    "                preds = model(xb)\n",
    "\n",
    "                pred_labels = preds.argmax(axis=1)\n",
    "                n = len(xb)\n",
    "                v_count += n\n",
    "                val_tot_acc  += mi.Tensor.accuracy(pred_labels, yb).item()*n\n",
    "                val_tot_loss += loss_func(preds,yb).item()*n\n",
    "                \n",
    "        print(f\"epoch {epoch + 1:02d}/{epochs:02d} - loss: {train_tot_loss/t_count:.4f} - acc: {train_tot_acc/t_count:.4f} - val_loss: {val_tot_loss/v_count:.4f} - val_acc: {val_tot_acc/v_count:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a27421-9ec4-4019-a6c3-d68c049b17be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 01/05 - loss: 0.3559 - acc: 0.8699 - val_loss: 0.4342 - val_acc: 0.8355\n",
      "epoch 02/05 - loss: 0.3415 - acc: 0.8731 - val_loss: 0.3908 - val_acc: 0.8585\n",
      "epoch 03/05 - loss: 0.3293 - acc: 0.8779 - val_loss: 0.4098 - val_acc: 0.8539\n",
      "epoch 04/05 - loss: 0.3203 - acc: 0.8815 - val_loss: 0.3903 - val_acc: 0.8627\n",
      "epoch 05/05 - loss: 0.3114 - acc: 0.8839 - val_loss: 0.3966 - val_acc: 0.8600\n"
     ]
    }
   ],
   "source": [
    "fit(5, 0.01, network, nn.CrossEntropyLoss(), optim.SGD, tr_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681d4df4-e96f-4a09-b498-bf36daa19fda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
