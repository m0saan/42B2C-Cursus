{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2389c9-a4f6-44e8-b0cd-c9f984b5f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfffdbb-db4b-4d2b-8904-4b8b34da0b98",
   "metadata": {},
   "source": [
    "# Exercise 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcd82ca-8645-4a4b-b2d4-206ae2302c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_(x):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of a vector.\n",
    "    Args:\n",
    "    x: has to be a numpy.ndarray of shape (m, 1).\n",
    "    Returns:\n",
    "    The sigmoid value as a numpy.ndarray of shape (m, 1).\n",
    "    None if x is an empty numpy.ndarray.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e3b21-a460-46cf-afb9-d6e458ed0054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01798621]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:\n",
    "x = np.array([[-4]])\n",
    "sigmoid_(x)\n",
    "# Output: array([[0.01798620996209156]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c752c4-f5b8-4a2b-bc6a-cc4f54b6cee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88079708]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "x = np.array([[2]])\n",
    "sigmoid_(x)\n",
    "# Output: array([[0.8807970779778823]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141a5aa-d62e-4329-96e7-9e447e274555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01798621],\n",
       "       [0.88079708],\n",
       "       [0.5       ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3:\n",
    "x = np.array([[-4], [2], [0]])\n",
    "sigmoid_(x)\n",
    "# Output: array([[0.01798620996209156], [0.8807970779778823], [0.5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84cbcaa-b7a7-42e4-9f93-1abd6cdedd9e",
   "metadata": {},
   "source": [
    "# Exercise 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010f3110-c864-47f8-b5d5-a99c2a8280d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_predict_(x, theta):\n",
    "    \"\"\"\n",
    "    Computes the vector of prediction y_hat from two non-empty numpy.ndarray.\n",
    "    \n",
    "    Args:\n",
    "    x: has to be an numpy.ndarray, a vector of dimension m * n.\n",
    "    theta: has to be an numpy.ndarray, a vector of dimension (n + 1) * 1.\n",
    "    \n",
    "    Returns:\n",
    "    y_hat as a numpy.ndarray, a vector of dimension m * 1.\n",
    "    None if x or theta are empty numpy.ndarray.\n",
    "    None if x or theta dimensions are not appropriate.\n",
    "    \n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    m,n = x.shape\n",
    "    x_bias = np.c_[np.ones((m, 1)), x]\n",
    "    return sigmoid_(np.dot(x_bias, theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52050ec5-d549-47a8-86db-0772cc75b41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98201379]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "x = np.array([4]).reshape((-1, 1))\n",
    "theta = np.array([[2], [0.5]])\n",
    "logistic_predict_(x, theta)\n",
    "# Output: array([[0.98201379]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50abd070-c63a-485d-b7f8-c702d3bd102c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98201379],\n",
       "       [0.99624161],\n",
       "       [0.97340301],\n",
       "       [0.99875204],\n",
       "       [0.90720705]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "x2 = np.array([[4], [7.16], [3.2], [9.37], [0.56]])\n",
    "theta2 = np.array([[2], [0.5]])\n",
    "logistic_predict_(x2, theta2)\n",
    "# Output: array([[0.98201379], [0.99624161], [0.97340301], [0.99875204], [0.90720705]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee30b01-e2ee-410a-b8dc-b730ba2b948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03916572],\n",
       "       [0.00045262],\n",
       "       [0.2890505 ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3\n",
    "x3 = np.array([[0, 2, 3, 4], [2, 4, 5, 5], [1, 3, 2, 7]])\n",
    "theta3 = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])\n",
    "logistic_predict_(x3, theta3)\n",
    "# Output: array([[0.03916572],[0.00045262],[0.2890505 ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d03ee5-8398-42da-af8c-342b7aed54d9",
   "metadata": {},
   "source": [
    "# Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ab00b2-17c5-49a7-80f3-1d6a6b3ea672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss_(y, y_hat, eps=1e-15):\n",
    "    \"\"\"\n",
    "    Computes the logistic loss value.\n",
    "    Args:\n",
    "    y: has to be an numpy.ndarray, a vector of shape m * 1.\n",
    "    y_hat: has to be an numpy.ndarray, a vector of shape m * 1.\n",
    "    eps: has to be a float, epsilon (default=1e-15)\n",
    "    Returns:\n",
    "    The logistic loss value as a float.\n",
    "    None on any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    # y_hat = np.clip(y_hat, eps, 1 - eps)\n",
    "    # loss = 0.0\n",
    "    # y, y_hat = y[:, 0], y_hat[:, 0]\n",
    "    # for i in range(len(y)):\n",
    "    #     loss -= y[i] * np.log(y_hat[i]) + (1 - y[i]) * np.log(1 - y_hat[i])\n",
    "    # return (1/x.shape[0]) * loss\n",
    "    m = y.shape[0]\n",
    "    y_hat = np.clip(y_hat, eps, 1 - eps)\n",
    "\n",
    "    loss_value = -1/m * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa56d151-5785-4579-ac54-4010d5c6358a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01814992791780973"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:\n",
    "y1 = np.array([1]).reshape((-1, 1))\n",
    "x1 = np.array([4]).reshape((-1, 1))\n",
    "theta1 = np.array([[2], [0.5]])\n",
    "y_hat1 = logistic_predict_(x1, theta1)\n",
    "log_loss_(y1, y_hat1)\n",
    "# Output: 0.01814992791780973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746ade2-2aaf-48d2-a739-dd8d706f31ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4825011602474483"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "y2 = np.array([[1], [0], [1], [0], [1]])\n",
    "x2 = np.array([[4], [7.16], [3.2], [9.37], [0.56]])\n",
    "theta2 = np.array([[2], [0.5]])\n",
    "y_hat2 = logistic_predict_(x2, theta2)\n",
    "log_loss_(y2, y_hat2)\n",
    "# Output: 2.4825011602474483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc5bc01-d403-460d-8606-650e185672e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9938533108607057"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3:\n",
    "y3 = np.array([[0], [1], [1]])\n",
    "x3 = np.array([[0, 2, 3, 4], [2, 4, 5, 5], [1, 3, 2, 7]])\n",
    "theta3 = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])\n",
    "y_hat3 = logistic_predict_(x3, theta3)\n",
    "log_loss_(y3, y_hat3)\n",
    "# Output: 2.9938533108607053"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdcefb-0463-4c46-99be-96d5fe40ef35",
   "metadata": {},
   "source": [
    "# Exercise 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5812410-75c7-442c-9d5e-daf12a48fe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_log_loss_(y, y_hat, eps=1e-15):\n",
    "    \"\"\"\n",
    "    Computes the logistic loss value.\n",
    "    Args:\n",
    "    y: has to be an numpy.ndarray, a vector of shape m * 1.\n",
    "    y_hat: has to be an numpy.ndarray, a vector of shape m * 1.\n",
    "    eps: has to be a float, epsilon (default=1e-15)\n",
    "    Returns:\n",
    "    The logistic loss value as a float.\n",
    "    None on any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    # y_hat = np.clip(y_hat, eps, 1 - eps)\n",
    "    # loss = 0.0\n",
    "    # y, y_hat = y[:, 0], y_hat[:, 0]\n",
    "    # for i in range(len(y)):\n",
    "    #     loss -= y[i] * np.log(y_hat[i]) + (1 - y[i]) * np.log(1 - y_hat[i])\n",
    "    # return (1/x.shape[0]) * loss\n",
    "    m = y.shape[0]\n",
    "    y_hat = np.clip(y_hat, eps, 1 - eps)\n",
    "\n",
    "    loss_value = -1/m * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345c02cf-32ad-4294-a57b-fee6aed4296a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01814992791780973"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:\n",
    "y1 = np.array([1]).reshape((-1, 1))\n",
    "x1 = np.array([4]).reshape((-1, 1))\n",
    "theta1 = np.array([[2], [0.5]])\n",
    "y_hat1 = logistic_predict_(x1, theta1)\n",
    "vec_log_loss_(y1, y_hat1)\n",
    "# Output: 0.01814992791780973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b995a5-ffaf-4730-962b-398325df7d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4825011602474483"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "y2 = np.array([[1], [0], [1], [0], [1]])\n",
    "x2 = np.array([[4], [7.16], [3.2], [9.37], [0.56]])\n",
    "theta2 = np.array([[2], [0.5]])\n",
    "y_hat2 = logistic_predict_(x2, theta2)\n",
    "vec_log_loss_(y2, y_hat2)\n",
    "# Output: 2.4825011602474483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bdb2a4-2d73-4d6d-84f4-bdcd33ebc35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9938533108607057"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3:\n",
    "y3 = np.array([[0], [1], [1]])\n",
    "x3 = np.array([[0, 2, 3, 4], [2, 4, 5, 5], [1, 3, 2, 7]])\n",
    "theta3 = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])\n",
    "y_hat3 = logistic_predict_(x3, theta3)\n",
    "vec_log_loss_(y3, y_hat3)\n",
    "# Output: 2.9938533108607053"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ada9e-8a38-408c-847f-149f52bf08b1",
   "metadata": {},
   "source": [
    "# Exercise 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a0412-3a62-4b5f-b312-e6368d4166d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_gradient(x, y, theta):\n",
    "    \"\"\"\n",
    "    Computes a gradient vector from three non-empty numpy.ndarray, with a for-loop. The three arrays must have compatiblArgs:\n",
    "    x: has to be an numpy.ndarray, a matrix of shape m * n.\n",
    "    y: has to be an numpy.ndarray, a vector of shape m * 1.\n",
    "    theta: has to be an numpy.ndarray, a vector of shape (n + 1) * 1.\n",
    "    \n",
    "    Returns:\n",
    "    The gradient as a numpy.ndarray, a vector of shape n * 1, containing the result of the formula for all j.\n",
    "    None if x, y, or theta are empty numpy.ndarray.\n",
    "    None if x, y and theta do not have compatible dimensions.\n",
    "    \n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    m,n = x.shape\n",
    "    y_hat = logistic_predict_(x, theta)\n",
    "    grad = np.zeros((n + 1, 1))\n",
    "\n",
    "    for i in range(m):\n",
    "        grad[0] += y_hat[i] - y[i]\n",
    "        for j in range(1, n + 1):\n",
    "            grad[j] += (y_hat[i] - y[i]) * x[i, j - 1]\n",
    "\n",
    "    return grad / m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b634f-cd1a-4a4a-bb37-518a693aaf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01798621],\n",
       "       [-0.07194484]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:\n",
    "y1 = np.array([1]).reshape((-1, 1))\n",
    "x1 = np.array([4]).reshape((-1, 1))\n",
    "theta1 = np.array([[2], [0.5]])\n",
    "log_gradient(x1, y1, theta1)\n",
    "# Output: array([[-0.01798621], [-0.07194484]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd8d72-0e93-4eb3-8d25-513f3a5daa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3715235 ],\n",
       "       [3.25647547]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "y2 = np.array([[1], [0], [1], [0], [1]])\n",
    "x2 = np.array([[4], [7.16], [3.2], [9.37], [0.56]])\n",
    "theta2 = np.array([[2], [0.5]])\n",
    "log_gradient(x2, y2, theta2)\n",
    "# Output: array([[0.3715235 ], [3.25647547]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72ff0b-d301-44d0-ba62-ba1258c7e7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55711039],\n",
       "       [-0.90334809],\n",
       "       [-2.01756886],\n",
       "       [-2.10071291],\n",
       "       [-3.27257351]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3:\n",
    "y3 = np.array([[0], [1], [1]])\n",
    "x3 = np.array([[0, 2, 3, 4], [2, 4, 5, 5], [1, 3, 2, 7]])\n",
    "theta3 = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])\n",
    "log_gradient(x3, y3, theta3)\n",
    "# Output: array([[-0.55711039], [-0.90334809], [-2.01756886], [-2.10071291], [-3.27257351]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b6e3e7-fdc6-4a75-b2de-3b1cd3d811e8",
   "metadata": {},
   "source": [
    "# Exercise 05 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925c53da-fa86-4c5c-964e-53e032e926ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_log_gradient(x, y, theta):\n",
    "    \"\"\"\n",
    "    Computes a gradient vector from three non-empty numpy.ndarray, without any for-loop. The three arrays must have compArgs:\n",
    "    x: has to be an numpy.ndarray, a matrix of shape m * n.\n",
    "    y: has to be an numpy.ndarray, a vector of shape m * 1.\n",
    "    theta: has to be an numpy.ndarray, a vector (n +1) * 1.\n",
    "    \n",
    "    Returns:\n",
    "    The gradient as a numpy.ndarray, a vector of shape n * 1, containg the result of the formula for all j.\n",
    "    None if x, y, or theta are empty numpy.ndarray.\n",
    "    None if x, y and theta do not have compatible shapes.\n",
    "    \n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    m, n = x.shape\n",
    "    X = np.c_[np.ones((m, 1)), x]\n",
    "    return 1/m * X.T@(logistic_predict_(x, theta) - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c442ee7-d20b-411f-baa2-a59410cb4d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01798621],\n",
       "       [-0.07194484]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:\n",
    "y1 = np.array([1]).reshape((-1, 1))\n",
    "x1 = np.array([4]).reshape((-1, 1))\n",
    "theta1 = np.array([[2], [0.5]])\n",
    "vec_log_gradient(x1, y1, theta1)\n",
    "# Output: array([[-0.01798621], [-0.07194484]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f7d8b-8e97-407f-b8e8-67c79032e8e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3715235 ],\n",
       "       [3.25647547]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "y2 = np.array([[1], [0], [1], [0], [1]])\n",
    "x2 = np.array([[4], [7.16], [3.2], [9.37], [0.56]])\n",
    "theta2 = np.array([[2], [0.5]])\n",
    "log_gradient(x2, y2, theta2)\n",
    "# Output: array([[0.3715235 ], [3.25647547]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60240330-d937-41cc-a24a-5d8a65b78441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55711039],\n",
       "       [-0.90334809],\n",
       "       [-2.01756886],\n",
       "       [-2.10071291],\n",
       "       [-3.27257351]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3:\n",
    "y3 = np.array([[0], [1], [1]])\n",
    "x3 = np.array([[0, 2, 3, 4], [2, 4, 5, 5], [1, 3, 2, 7]])\n",
    "theta3 = np.array([[-2.4], [-1.5], [0.3], [-1.4], [0.7]])\n",
    "log_gradient(x3, y3, theta3)\n",
    "# Output: array([[-0.55711039], [-0.90334809], [-2.01756886], [-2.10071291], [-3.27257351]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d9c88-93c5-4cf2-9e7d-97823c6313d5",
   "metadata": {},
   "source": [
    "# Exercise 06 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ce03be-91ae-424b-b196-7ff614515f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLogisticRegression():\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    My personnal logistic regression to classify things.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, theta, alpha=0.001, max_iter=1000):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.theta = theta\n",
    "\n",
    "\n",
    "    def predict_(self, x):\n",
    "        \n",
    "        def sigmoid_(x): return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "        m,n = x.shape\n",
    "        x_bias = np.c_[np.ones((m, 1)), x]\n",
    "        return sigmoid_(np.dot(x_bias, self.theta))\n",
    "        \n",
    "    def loss_elem_(self, y, yhat):\n",
    "        m = y.shape[0]\n",
    "        eps = 1e-15\n",
    "        y_hat = np.clip(yhat, eps, 1 - eps)\n",
    "\n",
    "        return y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat)\n",
    "\n",
    "\n",
    "    def loss_(self, X, y):\n",
    "        y_hat = self.predict_(X)\n",
    "        eps = 1e-15\n",
    "        m = y.shape[0]\n",
    "        y_hat = np.clip(y_hat, eps, 1 - eps)\n",
    "\n",
    "        loss_value = -1/m * np.sum(y * np.log(y_hat) + (1 - y) * np.log(1 - y_hat))\n",
    "        return loss_value\n",
    "    \n",
    "    \n",
    "    def fit_(self, x, y):\n",
    "        \n",
    "        def vec_log_gradient(x, y, theta):\n",
    "            m, n = x.shape\n",
    "            X = np.c_[np.ones((m, 1)), x]\n",
    "            return 1/m * X.T@(self.predict_(x) - y)\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            grad = vec_log_gradient(x, y, self.theta)\n",
    "            self.theta -= grad * self.alpha\n",
    "        return self.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12caa30-be03-4568-82ec-5de2d805867e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99930437],\n",
       "       [1.        ],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from my_logistic_regression import MyLogisticRegression as MyLR\n",
    "X = np.array([[1., 1., 2., 3.], [5., 8., 13., 21.], [3., 5., 9., 14.]])\n",
    "Y = np.array([[1], [0], [1]])\n",
    "thetas = np.array([[2], [0.5], [7.1], [-4.3], [2.09]])\n",
    "mylr = MyLogisticRegression(thetas)\n",
    "# Example 0:\n",
    "mylr.predict_(X)\n",
    "# Output: array([[0.99930437], [1. ], [1. ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78328dfe-00c5-46e4-b220-c37dc828294d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.513423954053735"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1:\n",
    "mylr.loss_(X,Y)\n",
    "# Output: 11.513157421577004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee289ee-afef-4752-958e-161f2a46d826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.11826435],\n",
       "       [ 0.10154334],\n",
       "       [ 6.43942899],\n",
       "       [-5.10817488],\n",
       "       [ 0.6212541 ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "mylr.fit_(X, Y)\n",
    "mylr.theta\n",
    "# Output: array([[ 2.11826435] [ 0.10154334] [ 6.43942899] [-5.10817488] [ 0.6212541 ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e780ae-cfb4-4278-aaed-1459c8892584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57606717],\n",
       "       [0.68599807],\n",
       "       [0.06562156]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 3:\n",
    "mylr.predict_(X)\n",
    "# Output: array([[0.57606717] [0.68599807] [0.06562156]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d281435-6c01-4d64-b780-9dd981fd1f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4779126923052321"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 4:\n",
    "mylr.loss_(X,Y)\n",
    "# Output: 1.4779126923052268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40acec3e-83ab-483e-a320-604c6ed85958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c278318-e0eb-4096-98b7-7ead390c84b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d855fbf7-9198-4180-869d-8414275c4e5e",
   "metadata": {},
   "source": [
    "# Exercise 08 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd8d7d9-d304-494d-9281-526762aca9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9179da8-4ac4-4076-8d06-7aab3d4eb726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score_(y, y_hat):\n",
    "    \"\"\"\n",
    "    Compute the accuracy score.\n",
    "    Args:\n",
    "    y:a numpy.ndarray for the correct labels\n",
    "    y_hat:a numpy.ndarray for the predicted labels\n",
    "    Returns:\n",
    "    The accuracy score as a float.\n",
    "    None on any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    correct_predictions = np.sum(y == y_hat)\n",
    "    total_predictions = y.size\n",
    "    \n",
    "    return correct_predictions / total_predictions\n",
    "    \n",
    "    \n",
    "def precision_score_(y, y_hat, pos_label=1):\n",
    "    \"\"\"\n",
    "    Compute the precision score.\n",
    "    Args:\n",
    "    y:a numpy.ndarray for the correct labels\n",
    "    y_hat:a numpy.ndarray for the predicted labels\n",
    "    pos_label: str or int, the class on which to report the precision_score (default=1)\n",
    "    Return:\n",
    "    The precision score as a float.\n",
    "    None on any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    tp = np.sum((y == pos_label) & (y_hat == pos_label))\n",
    "    fp = np.sum((y != pos_label) & (y_hat == pos_label))\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall_score_(y, y_hat, pos_label=1):\n",
    "    \"\"\"\n",
    "    Compute the recall score.\n",
    "    Args:\n",
    "    y:a numpy.ndarray for the correct labels\n",
    "    y_hat:a numpy.ndarray for the predicted labels\n",
    "    pos_label: str or int, the class on which to report the precision_score (default=1)\n",
    "    Return:\n",
    "    The recall score as a float.\n",
    "    None on any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    tp = np.sum((y == pos_label) & (y_hat == pos_label))\n",
    "    fn = np.sum((y == pos_label) & (y_hat != pos_label))\n",
    "    return tp / (tp + fn)\n",
    "    \n",
    "def f1_score_(y, y_hat, pos_label=1):\n",
    "    \"\"\"\n",
    "    Compute the f1 score.\n",
    "    Args:\n",
    "    y:a numpy.ndarray for the correct labels\n",
    "    y_hat:a numpy.ndarray for the predicted labels\n",
    "    pos_label: str or int, the class on which to report the precision_score (default=1)\n",
    "    Returns:\n",
    "    The f1 score as a float.\n",
    "    None on any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    precision, recall = precision_score_(y, y_hat, pos_label), recall_score_(y, y_hat, pos_label)\n",
    "    return (2 * precision * recall) / (precision + recall) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ac2ec5-54a9-45ec-97d3-2e3c15f68ee7",
   "metadata": {},
   "source": [
    "### Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11aeba7-b6fd-4b8c-87d7-cc188ae488e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array([1, 1, 0, 1, 0, 0, 1, 1]).reshape((-1, 1))\n",
    "y = np.array([1, 0, 0, 1, 0, 1, 0, 0]).reshape((-1, 1))\n",
    "## your implementation\n",
    "my_ = accuracy_score_(y, y_hat)\n",
    "## Output: 0.5\n",
    "## sklearn implementation\n",
    "sk_ = accuracy_score(y, y_hat)\n",
    "## Output: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec029183-e298-425c-809c-fcf0fa234baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_, sk_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded3780c-113e-4dbe-b031-9a4620c610bc",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026a890-86b9-4046-8df2-28bda9ef133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your implementation\n",
    "my_ = precision_score_(y, y_hat)\n",
    "## Output: 0.4\n",
    "## sklearn implementation\n",
    "sk_ = precision_score(y, y_hat)\n",
    "## Output: 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0999b1-3125-4dd5-a4b9-ca7ad9b8e956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_, sk_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fdce53-3aab-4602-aa05-6f5c7373abfd",
   "metadata": {},
   "source": [
    "### Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972738f8-4780-4645-8a99-4301f025ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your implementation\n",
    "my_ = recall_score_(y, y_hat)\n",
    "## Output: 0.6666666666666666\n",
    "## sklearn implementation\n",
    "sk_ = recall_score(y, y_hat)\n",
    "## Output: 0.6666666666666666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec07eff3-c5c1-4a7d-a44e-1bc7e7f111b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666666666666, 0.6666666666666666)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_, sk_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9c3bda-8906-4805-a3cd-ee2a3efa75af",
   "metadata": {},
   "source": [
    "### F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e0bd8-d582-418d-a17a-04d96c164741",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your implementation\n",
    "my_ = f1_score_(y, y_hat)\n",
    "## Output: 0.5\n",
    "## sklearn implementation\n",
    "sk_ = f1_score(y, y_hat)\n",
    "## Output: 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b1706f-f4cf-4550-baff-9eae1bc3294b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_, sk_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f207d9-620f-4304-a852-df4119b6a6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2:\n",
    "y_hat = np.array(['norminet', 'dog', 'norminet', 'norminet', 'dog', 'dog', 'dog', 'dog'])\n",
    "y = np.array(['dog', 'dog', 'norminet', 'norminet', 'dog', 'norminet', 'dog', 'norminet'])\n",
    "# Accuracy\n",
    "## your implementation\n",
    "assert accuracy_score_(y, y_hat) == accuracy_score(y, y_hat)\n",
    "assert precision_score_(y, y_hat, pos_label='dog') == precision_score(y, y_hat, pos_label='dog')\n",
    "assert recall_score_(y, y_hat, pos_label='dog') == recall_score(y, y_hat, pos_label='dog')\n",
    "assert f1_score_(y, y_hat, pos_label='dog') == f1_score(y, y_hat, pos_label='dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc52fde-91dc-47fc-8e87-5c4dde468bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e493b8b-311b-4ade-b6be-725d8ad0e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3:\n",
    "y_hat = np.array(['norminet', 'dog', 'norminet', 'norminet', 'dog', 'dog', 'dog', 'dog'])\n",
    "y = np.array(['dog', 'dog', 'norminet', 'norminet', 'dog', 'norminet', 'dog', 'norminet'])\n",
    "assert precision_score_(y, y_hat, pos_label='norminet') == precision_score(y, y_hat, pos_label='norminet')\n",
    "assert recall_score_(y, y_hat, pos_label='norminet') == recall_score(y, y_hat, pos_label='norminet')\n",
    "assert f1_score_(y, y_hat, pos_label='norminet') == f1_score(y, y_hat, pos_label='norminet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca8ea5-a05a-44d1-9dfa-749bfc75ff6c",
   "metadata": {},
   "source": [
    "# Exercise 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d2c38-9d4a-4ced-b6f1-32d41984b2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_(y_true, y_hat, labels=None):\n",
    "    \"\"\"\n",
    "    Compute confusion matrix to evaluate the accuracy of a classification.\n",
    "    Args:\n",
    "    y:a numpy.array for the correct labels\n",
    "    y_hat:a numpy.array for the predicted labels\n",
    "    labels: optional, a list of labels to index the matrix.\n",
    "    This may be used to reorder or select a subset of labels. (default=None)\n",
    "    df_option: optional, if set to True the function will return a pandas DataFrame\n",
    "    instead of a numpy array. (default=False)\n",
    "    Return:\n",
    "    The confusion matrix as a numpy array or a pandas DataFrame according to df_option value.\n",
    "    None if any error.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    \n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate((y_true, y_hat)))\n",
    "\n",
    "    matrix = np.zeros((len(labels), len(labels)))\n",
    "\n",
    "    for i, label1 in enumerate(labels):\n",
    "        for j, label2 in enumerate(labels):\n",
    "            matrix[i, j] = np.sum((y_true == label1) & (y_hat == label2))\n",
    "\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c12ff-0f23-4e88-8c36-ef2a813aa4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 2., 1.],\n",
       "       [1., 0., 2.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_hat = np.array([['norminet'], ['dog'], ['norminet'], ['norminet'], ['dog'], ['bird']])\n",
    "y = np.array([['dog'], ['dog'], ['norminet'], ['norminet'], ['dog'], ['norminet']])\n",
    "\n",
    "confusion_matrix_(y, y_hat)\n",
    "## Output:\n",
    "# array([[0 0 0]\n",
    "# [0 2 1]\n",
    "# [1 0 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c07e5-2ea3-4164-ab13-19a7069a0fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 2, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sklearn implementation\n",
    "confusion_matrix(y, y_hat)\n",
    "## Output:\n",
    "# array([[0 0 0]\n",
    "# [0 2 1]\n",
    "# [1 0 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf167ed-a8fd-485f-96b4-7e14d028f562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 1.],\n",
       "       [0., 2.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2:\n",
    "## your implementation\n",
    "confusion_matrix_(y, y_hat, labels=['dog', 'norminet'])\n",
    "## Output:\n",
    "# array([[2 1]\n",
    "# [0 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59064e93-6772-4651-8c00-a620c2b5606d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [0, 2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## sklearn implementation\n",
    "confusion_matrix(y, y_hat, labels=['dog', 'norminet'])\n",
    "## Output:\n",
    "# array([[2 1]\n",
    "# [0 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ab3a6-f270-46ba-b7fb-335ed54436f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
