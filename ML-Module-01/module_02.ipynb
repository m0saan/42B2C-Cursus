{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9d2f2-1628-49b4-9437-8aac3f908cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f31b10-5ee6-42c9-9577-f78d73ea0135",
   "metadata": {},
   "source": [
    "# Exercise 00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af9e47f-355a-42e9-90c6-1c78dbcb5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_predict(x, theta):\n",
    "    \"\"\"Computes the prediction vector y_hat from two non-empty numpy.array.\n",
    "    Args:\n",
    "    x: has to be an numpy.array, a matrix of dimension m * n.\n",
    "    theta: has to be an numpy.array, a vector of dimension (n + 1) * 1.\n",
    "    Return:\n",
    "    y_hat as a numpy.array, a vector of dimension m * 1.\n",
    "    None if x or theta are empty numpy.array.\n",
    "    None if x or theta dimensions are not matching.\n",
    "    None if x or theta is not of expected type.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852ce1e-8584-4330-abe3-0e6a61a66861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(1,13).reshape((4,-1))\n",
    "# Example 1:\n",
    "theta1 = np.array([5, 0, 0, 0]).reshape((-1, 1))\n",
    "simple_predict(x, theta1)\n",
    "# Ouput:\n",
    "array([[5.], [5.], [5.], [5.]])\n",
    "# Do you understand why y_hat contains only 5’s here?\n",
    "# Example 2:\n",
    "theta2 = np.array([0, 1, 0, 0]).reshape((-1, 1))\n",
    "simple_predict(x, theta2)\n",
    "# Output:\n",
    "array([[ 1.], [ 4.], [ 7.], [10.]])\n",
    "# Do you understand why y_hat == x[:,0] here?\n",
    "# Example 3:\n",
    "theta3 = np.array([-1.5, 0.6, 2.3, 1.98]).reshape((-1, 1))\n",
    "simple_predict(X, theta3)\n",
    "# Output:\n",
    "array([[ 9.64], [24.28], [38.92], [53.56]])\n",
    "# Example 4:\n",
    "theta4 = np.array([-3, 1, 2, 3.5]).reshape((-1, 1))\n",
    "simple_predict(x, theta4)\n",
    "# Output:\n",
    "array([[12.5], [32. ], [51.5], [71. ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e1124c-1c35-433c-b50d-9549e3c6184e",
   "metadata": {},
   "source": [
    "# Exercise 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a0468-9c94-4b97-a7a7-1cf49520ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_(x, theta):\n",
    "    \"\"\"Computes the prediction vector y_hat from two non-empty numpy.array.\n",
    "    Args:\n",
    "    x: has to be an numpy.array, a vector of dimensions m * n.\n",
    "    theta: has to be an numpy.array, a vector of dimensions (n + 1) * 1.\n",
    "    Return:\n",
    "    y_hat as a numpy.array, a vector of dimensions m * 1.\n",
    "    None if x or theta are empty numpy.array.\n",
    "    None if x or theta dimensions are not appropriate.\n",
    "    None if x or theta is not of expected type.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76806b29-b81d-4650-9dac-a85904a104c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Example 0:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m theta1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0.7\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m \u001b[43mgradient\u001b[49m(x, y, theta1)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Output: array([[-19.0342...], [-586.6687...]])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Example 1:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m theta2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.4\u001b[39m])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.arange(1,13).reshape((4,-1))\n",
    "# Example 1:\n",
    "theta1 = np.array([5, 0, 0, 0]).reshape((-1, 1))\n",
    "predict_(x, theta1)\n",
    "# Ouput:\n",
    "array([[5.], [5.], [5.], [5.]])\n",
    "# Do you understand why y_hat contains only 5’s here?\n",
    "# Example 2:\n",
    "theta2 = np.array([0, 1, 0, 0]).reshape((-1, 1))\n",
    "predict_(x, theta2)\n",
    "# Output:\n",
    "array([[ 1.], [ 4.], [ 7.], [10.]])\n",
    "# Do you understand why y_hat == x[:,0] here?\n",
    "# Example 3:\n",
    "theta3 = np.array([-1.5, 0.6, 2.3, 1.98]).reshape((-1, 1))\n",
    "predict_(X, theta3)\n",
    "# Output:\n",
    "array([[ 9.64], [24.28], [38.92], [53.56]])\n",
    "# Example 4:\n",
    "theta4 = np.array([-3, 1, 2, 3.5]).reshape((-1, 1))\n",
    "predict_(x, theta4)\n",
    "# Output:\n",
    "array([[12.5], [32. ], [51.5], [71. ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b70786-45d7-458d-8ed8-cb23d05367be",
   "metadata": {},
   "source": [
    "# Exercise 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba542e4a-862f-41c4-bca0-51b47be79b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_(y, y_hat):\n",
    "    \"\"\"Computes the mean squared error of two non-empty numpy.array, without any for loop.\n",
    "    The two arrays must have the same dimensions.\n",
    "    Args:\n",
    "    y: has to be an numpy.array, a vector.\n",
    "    y_hat: has to be an numpy.array, a vector.\n",
    "    Return:\n",
    "    The mean squared error of the two vectors as a float.\n",
    "    None if y or y_hat are empty numpy.array.\n",
    "    None if y and y_hat does not share the same dimensions.\n",
    "    None if y or y_hat is not of expected type.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3803df9-b347-477f-b435-d8e579f30ad0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m theta1\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Output: array([[1.40709365], [1.1150909 ]])\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Example 1:\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mpredict\u001b[49m(x, theta1)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Output:\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# array([[15.3408728 ],\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# [25.38243697],\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# [36.59126492],\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# [55.95130097],\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# [65.53471499]])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([0, 15, -9, 7, 12, 3, -21]).reshape((-1, 1))\n",
    "Y = np.array([2, 14, -13, 5, 12, 4, -19]).reshape((-1, 1))\n",
    "# Example 1:\n",
    "loss_(X, Y)\n",
    "# Output:\n",
    "2.142857142857143\n",
    "# Example 2:\n",
    "loss_(X, X)\n",
    "# Output:\n",
    "0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5459f8e9-b28a-4930-be44-b36b0d843cf1",
   "metadata": {},
   "source": [
    "# Exercise 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c028f-68f2-4d7a-bea1-389cb1b0a348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y, theta):\n",
    "    \"\"\"Computes a gradient vector from three non-empty numpy.array, without any for-loop.\n",
    "    The three arrays must have the compatible dimensions.\n",
    "    Args:\n",
    "    x: has to be an numpy.array, a matrix of dimension m * n.\n",
    "    y: has to be an numpy.array, a vector of dimension m * 1.\n",
    "    theta: has to be an numpy.array, a vector (n +1) * 1.\n",
    "    Return:\n",
    "    The gradient as a numpy.array, a vector of dimensions n * 1,\n",
    "    containg the result of the formula for all j.\n",
    "    None if x, y, or theta are empty numpy.array.\n",
    "    None if x, y and theta do not have compatible dimensions.\n",
    "    None if x, y or theta is not of expected type.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d115ed-6d3c-49bf-a22e-58032d06c47b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'my_linear_regression'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_linear_regression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MyLinearRegression \u001b[38;5;28;01mas\u001b[39;00m MyLR\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m12.4956442\u001b[39m], [\u001b[38;5;241m21.5007972\u001b[39m], [\u001b[38;5;241m31.5527382\u001b[39m], [\u001b[38;5;241m48.9145838\u001b[39m], [\u001b[38;5;241m57.5088733\u001b[39m]])\n\u001b[1;32m      4\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m37.4013816\u001b[39m], [\u001b[38;5;241m36.1473236\u001b[39m], [\u001b[38;5;241m45.7655287\u001b[39m], [\u001b[38;5;241m46.6793434\u001b[39m], [\u001b[38;5;241m59.5585554\u001b[39m]])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'my_linear_regression'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([\n",
    "[ -6, -7, -9],\n",
    "[ 13, -2, 14],\n",
    "[ -7, 14, -1],\n",
    "[ -8, -4, 6],\n",
    "[ -5, -9, 6],\n",
    "[ 1, -5, 11],\n",
    "[ 9, -11, 8]])\n",
    "y = np.array([2, 14, -13, 5, 12, 4, -19]).reshape((-1, 1))\n",
    "theta1 = np.array([3,0.5,-6]).reshape((-1, 1))\n",
    "# Example :\n",
    "gradient(x, y, theta1)\n",
    "# Output:\n",
    "array([[ -33.71428571], [ -37.35714286], [183.14285714], [-393.]])\n",
    "# Example :\n",
    "theta2 = np.array([0,0,0]).reshape((-1, 1))\n",
    "gradient(x, y, theta2)\n",
    "# Output:\n",
    "array([[ -0.71428571], [ 0.85714286], [23.28571429], [-26.42857143]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e050a76-7f82-4fb2-a9db-51524bc113b2",
   "metadata": {},
   "source": [
    "# Exercise 04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cac207d-2e4c-4e1b-9a18-ccb196e4af61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mylinearregression'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmylinearregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MyLinearRegression \u001b[38;5;28;01mas\u001b[39;00m MyLR\n\u001b[1;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mare_blue_pills_magic.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m Xpill \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[Micrograms])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mylinearregression'"
     ]
    }
   ],
   "source": [
    "def fit_(x, y, theta, alpha, max_iter):\n",
    "\"\"\"\n",
    "Description:\n",
    "Fits the model to the training dataset contained in x and y.\n",
    "Args:\n",
    "x: has to be a numpy.array, a matrix of dimension m * n:\n",
    "(number of training examples, number of features).\n",
    "y: has to be a numpy.array, a vector of dimension m * 1:\n",
    "(number of training examples, 1).\n",
    "theta: has to be a numpy.array, a vector of dimension (n + 1) * 1:\n",
    "(number of features + 1, 1).\n",
    "alpha: has to be a float, the learning rate\n",
    "max_iter: has to be an int, the number of iterations done during the gradient descent\n",
    "Return:\n",
    "new_theta: numpy.array, a vector of dimension (number of features + 1, 1).\n",
    "None if there is a matching dimension problem.\n",
    "None if x, y, theta, alpha or max_iter is not of expected type.\n",
    "Raises:\n",
    "This function should not raise any Exception.\n",
    "\"\"\"\n",
    "... your code here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787f2608-eef7-4ae7-aad8-4ecc2711b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([[0.2, 2., 20.], [0.4, 4., 40.], [0.6, 6., 60.], [0.8, 8., 80.]])\n",
    "y = np.array([[19.6], [-2.8], [-25.2], [-47.6]])\n",
    "theta = np.array([[42.], [1.], [1.], [1.]])\n",
    "# Example 0:\n",
    "theta2 = fit_(x, y, theta, alpha = 0.0005, max_iter=42000)\n",
    "theta2\n",
    "# Output:\n",
    "array([[41.99..],[0.97..], [0.77..], [-1.20..]])\n",
    "# Example 1:\n",
    "predict_(x, theta2)\n",
    "# Output:\n",
    "array([[19.5992..], [-2.8003..], [-25.1999..], [-47.5996..]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafd4bc7-f236-49c6-8578-ad907b8c8c80",
   "metadata": {},
   "source": [
    "# Exercise 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c833c8cb-12be-494c-872a-df5709be66f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mylinearregression import MyLinearRegression as MyLR\n",
    "X = np.array([[1., 1., 2., 3.], [5., 8., 13., 21.], [34., 55., 89., 144.]])\n",
    "Y = np.array([[23.], [48.], [218.]])\n",
    "mylr = MyLR([[1.], [1.], [1.], [1.], [1]])\n",
    "# Example 0:\n",
    "y_hat = mylr.predict_(X)\n",
    "# Output:\n",
    "array([[8.], [48.], [323.]])\n",
    "# Example 1:\n",
    "mylr.loss_elem_(Y, y_hat)\n",
    "# Output:\n",
    "array([[225.], [0.], [11025.]])\n",
    "# Example 2:\n",
    "mylr.loss_(Y, y_hat)\n",
    "# Output:\n",
    "1875.0\n",
    "# Example 3:\n",
    "mylr.alpha = 1.6e-4\n",
    "mylr.max_iter = 200000\n",
    "mylr.fit_(X, Y)\n",
    "mylr.theta\n",
    "# Output:\n",
    "array([[18.188..], [2.767..], [-0.374..], [1.392..], [0.017..]])\n",
    "# Example 4:\n",
    "y_hat = mylr.predict_(X)\n",
    "# Output:\n",
    "array([[23.417..], [47.489..], [218.065...]])\n",
    "# Example 5:\n",
    "mylr.loss_elem_(Y, y_hat)\n",
    "# Output:\n",
    "array([[0.174..], [0.260..], [0.004..]])\n",
    "# Example 6:\n",
    "mylr.loss_(Y, y_hat)\n",
    "# Output:\n",
    "0.0732.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6326470e-8cd1-4d71-89ca-0c5b440b020e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example 1:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m21\u001b[39m])\n\u001b[1;32m      3\u001b[0m zscore(X)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Output:\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "290e60a2-6ff6-4f3c-b222-eac4a65c70c8",
   "metadata": {},
   "source": [
    "# Exercise 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d459b1-ae2c-402b-8b8a-ba7fb3d01a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mylinearregression import MyLinearRegression as MyLR\n",
    "data = pd.read_csv(\"spacecraft_data.csv\")\n",
    "X = np.array(data[[’Age’]])\n",
    "Y = np.array(data[[’Sell_price’]])\n",
    "myLR_age = MyLR(theta = [[1000.0], [-1.0]], alpha = 2.5e-5, max_iter = 100000)\n",
    "myLR_age.fit_(X[:,0].reshape(-1,1), Y)\n",
    "y_pred = myLR_age.predict_(X[:,0].reshape(-1,1))\n",
    "myLR_age.mse_(y_pred,Y)\n",
    "#Output\n",
    "55736.86719..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99af07d-4e70-4079-addd-8643e657ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mylinearregression import MyLinearRegression as MyLR\n",
    "data = pd.read_csv(\"spacecraft_data.csv\")\n",
    "X = np.array(data[[’Age’,’Thrust_power’,’Terameters’]])\n",
    "Y = np.array(data[[’Sell_price’]])\n",
    "my_lreg = MyLR(theta = [1.0, 1.0, 1.0, 1.0], , alpha = 1e-4, max_iter = 600000)\n",
    "# Example 0:\n",
    "my_lreg.mse_(X,Y)\n",
    "# Output:\n",
    "144044.877...\n",
    "# Example 1:\n",
    "my_lreg.fit_(X,Y)\n",
    "my_lreg.theta\n",
    "# Output:\n",
    "array([[334.994...],[-22.535...],[5.857...],[-2.586...]])\n",
    "# Example 2:\n",
    "my_lreg.mse_(X,Y)\n",
    "# Output:\n",
    "586.896999..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b3151-8c69-4fab-a8c9-fd23eb61af18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1:\n",
    "X = np.array([0, 15, -9, 7, 12, 3, -21]).reshape((-1, 1))\n",
    "minmax(X)\n",
    "# Output:\n",
    "array([0.58333333, 1. , 0.33333333, 0.77777778, 0.91666667,\n",
    "0.66666667, 0. ])\n",
    "# Example 2:\n",
    "Y = np.array([2, 14, -13, 5, 12, 4, -19]).reshape((-1, 1))\n",
    "minmax(Y)\n",
    "# Output:\n",
    "array([0.63636364, 1. , 0.18181818, 0.72727273, 0.93939394,\n",
    "0.6969697 , 0. ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91d44c-d0cc-49d5-a299-d9f6fcd32835",
   "metadata": {},
   "source": [
    "# Exercise 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6469086-2904-45ce-abf3-7ed7e98456e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_polynomial_features(x, power):\n",
    "    \"\"\"Add polynomial features to vector x by raising its values up to the power given in argument.\n",
    "    Args:\n",
    "    x: has to be an numpy.array, a vector of dimension m * 1.\n",
    "    power: has to be an int, the power up to which the components of vector x are going to be raised.\n",
    "    Return:\n",
    "    The matrix of polynomial features as a numpy.array, of dimension m * n,\n",
    "    containing the polynomial feature values for all training examples.\n",
    "    None if x is an empty numpy.array.\n",
    "    None if x or power is not of expected type.\n",
    "    Raises:\n",
    "    This function should not raise any Exception.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e26151-4521-49dc-aaf4-92a366a95793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.arange(1,6).reshape(-1, 1)\n",
    "# Example 0:\n",
    "add_polynomial_features(x, 3)\n",
    "# Output:\n",
    "array([[ 1, 1, 1],\n",
    "[ 2, 4, 8],\n",
    "[ 3, 9, 27],\n",
    "[ 4, 16, 64],\n",
    "[ 5, 25, 125]])\n",
    "# Example 1:\n",
    "add_polynomial_features(x, 6)\n",
    "# Output:\n",
    "array([[ 1, 1, 1, 1, 1, 1],\n",
    "[ 2, 4, 8, 16, 32, 64],\n",
    "[ 3, 9, 27, 81, 243, 729],\n",
    "[ 4, 16, 64, 256, 1024, 4096],\n",
    "[ 5, 25, 125, 625, 3125, 15625]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5b6c6-fd0f-4a1e-a479-2d04c018beb7",
   "metadata": {},
   "source": [
    "# Exercise 08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8058f42d-ddfe-4609-8378-c2c0c9672f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1,11).reshape(-1,1)\n",
    "y = np.array([[ 1.39270298],\n",
    "[ 3.88237651],\n",
    "[ 4.37726357],\n",
    "[ 4.63389049],\n",
    "[ 7.79814439],\n",
    "[ 6.41717461],\n",
    "[ 8.63429886],\n",
    "[ 8.19939795],\n",
    "[10.37567392],\n",
    "[10.68238222]])\n",
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09962e24-477f-4368-9271-78ea03bd7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polynomial_model import add_polynomial_features\n",
    "from mylinearregression import MyLinearRegression as MyLR\n",
    "# Build the model:\n",
    "x_ = add_polynomial_features(x, 3)\n",
    "my_lr = MyLR(np.ones(4).reshape(-1,1)).fit_(x_, y)\n",
    "# Plot:\n",
    "## To get a smooth curve, we need a lot of data points\n",
    "continuous_x = np.arange(1,10.01, 0.01).reshape(-1,1)\n",
    "x_ = add_polynomial_features(continuous_x, 3)\n",
    "y_hat = my_lr.predict_(continuous_x)\n",
    "plt.scatter(x,y)\n",
    "plt.plot(continuous_x, y_hat, color=’orange’)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299eab4-8a85-4443-a582-06935895fd81",
   "metadata": {},
   "source": [
    "# Exercise 09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee15a2f-8e0a-46b6-89aa-2c1200650463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
